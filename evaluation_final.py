import os
import sys
import glob
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tabulate import tabulate
from datetime import datetime

# ====================================================
# [1] ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ====================================================
def find_latest_result(pattern):
    """ì£¼ì–´ì§„ íŒ¨í„´ì— ë§ëŠ” ê°€ì¥ ìµœì‹  íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    files = glob.glob(pattern)
    if not files: return None
    return max(files, key=os.path.getctime)

def standardize_columns(df):
    """ë‹¤ì–‘í•œ ì´ë¦„ì˜ ì»¬ëŸ¼ì„ í‘œì¤€ ì´ë¦„ìœ¼ë¡œ í†µì¼í•©ë‹ˆë‹¤."""
    if df.empty: return df
    
    # ê³µë°± ì œê±°
    df.columns = df.columns.str.strip()
    
    rename_map = {
        # Accuracy
        'Accuracy': 'Acc', 'Test Acc': 'Acc', 'Test_Acc': 'Acc',
        'DNN_Acc': 'Acc', 'RF_Acc': 'Acc',
        
        # F1 Score
        'F1_Score': 'F1', 'F1_Defective': 'F1', 'Test F1': 'F1', 'Test_F1': 'F1',
        'DNN_F1': 'F1', 'RF_F1': 'F1',
        
        # MCC
        'Test MCC': 'MCC', 'Test_MCC': 'MCC', 
        'DNN_MCC': 'MCC', 'RF_MCC': 'MCC', 'MCC Score': 'MCC',
        
        # Complexity
        'Complexity': 'Cplx', 'size_score': 'Cplx',
        'Weighted_Cplx': 'W_Cplx', 'weighted_score': 'W_Cplx'
    }
    
    df = df.rename(columns=rename_map)
    
    # í•„ìˆ˜ ìˆ˜ì¹˜ ì»¬ëŸ¼ 0.0 ì´ˆê¸°í™”
    for col in ['Acc', 'F1', 'MCC']:
        if col not in df.columns: df[col] = 0.0
            
    # ë³µì¡ë„ ì»¬ëŸ¼ ì²˜ë¦¬
    for col in ['Cplx', 'W_Cplx']:
        if col not in df.columns:
            if col == 'W_Cplx' and 'Cplx' in df.columns:
                df['W_Cplx'] = df['Cplx']
            else:
                df[col] = 0.0
                
    return df

def load_chirps_formulas():
    """CHIRPS(RF) ê·œì¹™ ìˆ˜ì‹ì„ ë¡œë“œí•©ë‹ˆë‹¤ (ë¹„êµìš©)."""
    base_dir = "analysis_results/Piecewise"
    formula_map = {}
    if not os.path.exists(base_dir): return formula_map
        
    for dataset_name in os.listdir(base_dir):
        path = os.path.join(base_dir, dataset_name, "piecewise_formulas_metrics.csv")
        if os.path.exists(path):
            try:
                df = pd.read_csv(path)
                if not df.empty:
                    top = df.sort_values(by='Importance', ascending=False).iloc[0]
                    formula_map[dataset_name] = f"[{top['Feature']}] {top['Formula']}"
            except: pass
    return formula_map

# ====================================================
# [2] ë°ì´í„° ë¡œë“œ ë° í†µí•©
# ====================================================
def load_and_merge_results():
    print("ğŸ“‚ ê²°ê³¼ íŒŒì¼ ë¡œë”© ë° í†µí•© ì¤‘...")
    dfs = []

    # 1. DNN (Baseline)
    dnn_file = find_latest_result("optuna_dnn_results*.csv")
    if dnn_file:
        print(f"   â–¶ DNN found: {dnn_file}")
        df = pd.read_csv(dnn_file)
        df = standardize_columns(df)
        df['Model'] = 'DNN'
        df['Type'] = 'Baseline'
        dfs.append(df)

    # 2. Random Forest (Baseline)
    rf_file = find_latest_result("optuna_rf_results*.csv")
    if rf_file:
        print(f"   â–¶ RF found: {rf_file}")
        df = pd.read_csv(rf_file)
        df = standardize_columns(df)
        df['Model'] = 'RF'
        df['Type'] = 'Baseline'
        dfs.append(df)

    # 3. MOGA Variants (Ours) - 'final_comparison' íŒ¨í„´ ê²€ìƒ‰
    moga_file = find_latest_result("final_comparison_*.csv")
    if moga_file:
        print(f"   â–¶ MOGA Variants found: {moga_file}")
        df = pd.read_csv(moga_file)
        df = standardize_columns(df)
        
        # Variant ì»¬ëŸ¼ì„ Model ì´ë¦„ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: "1. Standard" -> "GP-Standard")
        if 'Variant' in df.columns:
            def clean_variant_name(name):
                # "1. Standard" -> "Standard"
                clean_name = name.split('. ')[-1] if '. ' in str(name) else str(name)
                # "RL + Seeding" -> "RL+Seed" (ê·¸ë˜í”„ ê³µê°„ ì ˆì•½)
                clean_name = clean_name.replace("Seeding", "Seed").replace(" + ", "+")
                return f"GP-{clean_name}"
            
            df['Model'] = df['Variant'].apply(clean_variant_name)
        else:
            df['Model'] = 'GP-Unknown'
            
        df['Type'] = 'Proposed'
        dfs.append(df)
    else:
        print("âš ï¸ MOGA Variant ê²°ê³¼ íŒŒì¼(final_comparison_*.csv)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if not dfs:
        return pd.DataFrame()

    # í†µí•© ë° ì»¬ëŸ¼ ì •ë¦¬
    final_df = pd.concat(dfs, ignore_index=True)
    
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    req_cols = ['Dataset', 'Model', 'Type', 'Acc', 'F1', 'MCC', 'Cplx', 'W_Cplx', 'Formula']
    for c in req_cols:
        if c not in final_df.columns: final_df[c] = pd.NA
            
    # ìˆ«ìí˜• ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    final_df[['Acc', 'F1', 'MCC', 'Cplx', 'W_Cplx']] = final_df[['Acc', 'F1', 'MCC', 'Cplx', 'W_Cplx']].fillna(0.0)
    
    return final_df

# ====================================================
# [3] ì‹œê°í™” ë° ë¶„ì„ ì¶œë ¥
# ====================================================
def plot_comprehensive_comparison(df):
    """ëª¨ë“  ëª¨ë¸(Baseline + Variants)ì„ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„"""
    if df.empty: return

    save_dir = "final_evaluation_plots"
    os.makedirs(save_dir, exist_ok=True)
    
    # ëª¨ë¸ ìˆœì„œ ì •ë ¬ (Baseline ë¨¼ì €, ê·¸ ë‹¤ìŒ GP Variants)
    models = sorted(df['Model'].unique())
    # ì›í•˜ëŠ” ìˆœì„œê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ ì§€ì • (ì˜ˆ: DNN, RF, GP-Standard, ...)
    custom_order = [m for m in models if 'DNN' in m] + \
                   [m for m in models if 'RF' in m] + \
                   sorted([m for m in models if 'GP' in m])
    
    sns.set(style="whitegrid")
    metrics = ['MCC', 'F1']
    
    for metric in metrics:
        plt.figure(figsize=(14, 7))
        
        # ë§‰ëŒ€ ê·¸ë˜í”„
        ax = sns.barplot(
            data=df, 
            x='Dataset', 
            y=metric, 
            hue='Model', 
            hue_order=custom_order,
            palette='viridis',  # ë˜ëŠ” 'Paired', 'rocket' ë“±
            edgecolor='black',
            linewidth=0.8
        )
        
        plt.title(f'Comprehensive Comparison: {metric} Score', fontsize=16, fontweight='bold')
        plt.ylabel(metric, fontsize=14)
        plt.xlabel('Dataset', fontsize=14)
        plt.ylim(0, 1.05)
        plt.legend(title='Model', bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)
        plt.grid(axis='y', linestyle='--', alpha=0.5)
        
        plt.tight_layout()
        filename = f"{save_dir}/All_Models_{metric}.png"
        plt.savefig(filename, dpi=300)
        plt.close()
        print(f"ğŸ“Š ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {filename}")

def print_summary_tables(df):
    """ì„±ëŠ¥ ë° ë³µì¡ë„ ìš”ì•½ í…Œì´ë¸” ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ† Final Evaluation Summary")
    print("="*80)
    
    datasets = sorted(df['Dataset'].unique())
    
    # 1. Performance Summary (MCC ê¸°ì¤€ Best)
    print("\nğŸ“Œ Table 1: Best Model per Dataset (Target: MCC)")
    perf_data = []
    
    for ds in datasets:
        sub = df[df['Dataset'] == ds]
        if sub.empty: continue
        
        # Best MCC ì°¾ê¸°
        best_row = sub.loc[sub['MCC'].idxmax()]
        
        # DNN, RF ì ìˆ˜ ì°¾ê¸° (ë¹„êµìš©)
        dnn_score = sub[sub['Model'] == 'DNN']['MCC'].max()
        rf_score = sub[sub['Model'] == 'RF']['MCC'].max()
        
        # GP í‰ê· /ìµœê³  ì ìˆ˜
        gp_rows = sub[sub['Model'].str.contains("GP")]
        gp_best_score = gp_rows['MCC'].max() if not gp_rows.empty else 0.0
        
        perf_data.append([
            ds, 
            f"{dnn_score:.4f}", 
            f"{rf_score:.4f}", 
            f"{gp_best_score:.4f}", 
            f"{best_row['Model']} ({best_row['MCC']:.4f})"
        ])
        
    headers = ["Dataset", "DNN", "RF", "Best GP", "Winner (Model)"]
    print(tabulate(perf_data, headers=headers, tablefmt="fancy_grid"))
    
    # 2. GP Variants Comparison
    print("\nğŸ“Œ Table 2: GP Variants Comparison (Average MCC)")
    # GP ëª¨ë¸ë“¤ë§Œ í•„í„°ë§
    gp_df = df[df['Model'].str.contains("GP")]
    if not gp_df.empty:
        avg_mcc = gp_df.groupby('Model')['MCC'].mean().sort_values(ascending=False)
        var_data = [[m, f"{s:.4f}"] for m, s in avg_mcc.items()]
        print(tabulate(var_data, headers=["GP Variant", "Avg MCC"], tablefmt="simple"))
        
    # 3. Complexity & Formula
    print("\nğŸ“Œ Table 3: Complexity & Interpretability (Best GP vs RF)")
    cplx_data = []
    chirps_rules = load_chirps_formulas()
    
    for ds in datasets:
        sub = df[df['Dataset'] == ds]
        
        # RF Formula
        rf_form = chirps_rules.get(ds, "(No Rule)")
        rf_cplx = sub[sub['Model'] == 'RF']['Cplx'].max()
        if pd.isna(rf_cplx): rf_cplx = 0
        
        # Best GP Formula (MCC ê¸°ì¤€ 1ë“± GP)
        gp_sub = sub[sub['Model'].str.contains("GP")]
        if not gp_sub.empty:
            best_gp = gp_sub.loc[gp_sub['MCC'].idxmax()]
            gp_model = best_gp['Model']
            gp_cplx = best_gp['Cplx']
            gp_form = str(best_gp['Formula'])[:50] + "..." if len(str(best_gp['Formula'])) > 50 else str(best_gp['Formula'])
        else:
            gp_model, gp_cplx, gp_form = "-", 0, "-"
            
        cplx_data.append([ds, f"RF (Sz:{int(rf_cplx)})", rf_form[:40]+".."])
        cplx_data.append(["", f"{gp_model} (Sz:{int(gp_cplx)})", gp_form])
        cplx_data.append(["-", "-", "-"]) # êµ¬ë¶„ì„  ì—­í• 
        
    print(tabulate(cplx_data, headers=["Dataset", "Model (Size)", "Formula Snippet"], tablefmt="plain"))

# ====================================================
# [Main] ì‹¤í–‰
# ====================================================
if __name__ == "__main__":
    final_df = load_and_merge_results()
    
    if not final_df.empty:
        # ë°ì´í„° ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_name = f"final_comprehensive_results_{timestamp}.csv"
        final_df.to_csv(csv_name, index=False)
        print(f"\nğŸ’¾ í†µí•© ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_name}")
        
        # ê·¸ë˜í”„ ë° í…Œì´ë¸” ì¶œë ¥
        plot_comprehensive_comparison(final_df)
        print_summary_tables(final_df)
    else:
        print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")