# classifiers/classifier_pytorch.py
import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef
from tabulate import tabulate
from tqdm import tqdm
from util import load_data
from datetime import datetime

# ë°ì´í„°ì…‹ ì´ë¦„ ì •ì˜
DATASET_NAMES = ['CM1', 'JM1', 'KC1', 'KC3', 'MC1', 'MC2', 'MW1', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5']

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
EPOCHS = 100
BATCH_SIZE = 32
LEARNING_RATE = 0.005


class DefectDataset(Dataset):
    """
    PyTorch Dataset í´ë˜ìŠ¤: ê²°í•¨ ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë³€í™˜
    """
    def __init__(self, X_data, y_data):
        self.X_data = torch.tensor(X_data.values, dtype=torch.float32)
        self.y_data = torch.tensor(y_data.values, dtype=torch.float32).unsqueeze(1)

    def __len__(self):
        return len(self.X_data)

    def __getitem__(self, index):
        return self.X_data[index], self.y_data[index]


class DefectClassifier(nn.Module):
    """
    PyTorch ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜: 2ê°œì˜ Hidden Layerë¥¼ ê°€ì§„ DNN
    """
    def __init__(self, input_size, hidden_size=64, output_size=1, dropout_rate=0.2):
        super(DefectClassifier, self).__init__()
        self.layer_1 = nn.Linear(input_size, hidden_size)
        self.bn1 = nn.BatchNorm1d(hidden_size)
        self.layer_2 = nn.Linear(hidden_size, hidden_size // 2)
        self.bn2 = nn.BatchNorm1d(hidden_size // 2)
        self.layer_out = nn.Linear(hidden_size // 2, output_size)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=dropout_rate)

    def forward(self, x):
        x = self.relu(self.bn1(self.layer_1(x)))
        x = self.dropout(x)
        x = self.relu(self.bn2(self.layer_2(x)))
        x = self.dropout(x)
        x = self.layer_out(x)
        return x


def train_and_evaluate_pytorch(dataset_name):
    """
    íŠ¹ì • ë°ì´í„°ì…‹ì— ëŒ€í•´ PyTorch ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€(Accuracy, F1, MCC)í•˜ëŠ” í•¨ìˆ˜
    """
    print(f"ğŸš€ Processing {dataset_name}...", end=" ")
    
    X_train, y_train, X_test, y_test = load_data(dataset_name, data_type='pt')

    if X_train is None:
        print("Skipped (Data Not Found)")
        return None

    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
    train_dataset = DefectDataset(X_train, y_train)
    test_dataset = DefectDataset(X_test, y_test)
    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)

    # ëª¨ë¸ ì´ˆê¸°í™”
    INPUT_SIZE = X_train.shape[1]
    
    # í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°
    pos_count = y_train.sum()
    neg_count = len(y_train) - pos_count
    pos_weight = torch.tensor([neg_count / pos_count if pos_count > 0 else 1.0], dtype=torch.float32)

    model = DefectClassifier(INPUT_SIZE)
    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # í•™ìŠµ ë£¨í”„ (tqdm ë°”ë¥¼ ì˜†ì— ì§§ê²Œ í‘œì‹œí•˜ê±°ë‚˜ ìƒëµí•˜ì—¬ ë¡œê·¸ ê°€ë…ì„± ë†’ì„)
    model.train()
    
    # [ìˆ˜ì •] tqdmì„ epoch ë£¨í”„ì— ì ìš©í•˜ë˜, leave=Falseë¡œ ì„¤ì •í•˜ì—¬ ì™„ë£Œ í›„ ì‚¬ë¼ì§€ê²Œ í•˜ê±°ë‚˜
    # ê°„ë‹¨í•˜ê²Œ ì (.)ìœ¼ë¡œ ì§„í–‰ìƒí™©ì„ í‘œì‹œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” barë¥¼ ìœ ì§€í•˜ë˜ leave=Falseë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    with tqdm(range(EPOCHS), desc=f"   Training {dataset_name}", leave=False, unit="epoch") as pbar:
        for epoch in pbar:
            epoch_loss = 0.0
            for X_batch, y_batch in train_loader:
                optimizer.zero_grad()
                y_pred_logits = model(X_batch)
                loss = criterion(y_pred_logits, y_batch)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
            
            # ì§„í–‰ë¥  ë°”ì— í˜„ì¬ Loss í‘œì‹œ
            pbar.set_postfix({'loss': f'{epoch_loss/len(train_loader):.4f}'})

    # í‰ê°€ ëª¨ë“œ
    model.eval()

    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)
    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)

    with torch.no_grad():
        y_pred_logits = model(X_test_tensor)
        y_pred_prob = torch.sigmoid(y_pred_logits)
        y_pred_tag = torch.round(y_pred_prob)

    # Tensor -> Numpy ë³€í™˜
    y_test_np = y_test_tensor.squeeze().numpy()
    y_pred_np = y_pred_tag.squeeze().numpy()

    # ì§€í‘œ ê³„ì‚°
    accuracy = accuracy_score(y_test_np, y_pred_np)
    f1_defective = f1_score(y_test_np, y_pred_np, pos_label=1, average='binary', zero_division=0)
    mcc_score = matthews_corrcoef(y_test_np, y_pred_np) # MCC ì¶”ê°€

    print(f"Done. (Acc: {accuracy:.4f}, F1: {f1_defective:.4f}, MCC: {mcc_score:.4f})")

    return {
        'Dataset': dataset_name, 
        'Accuracy': accuracy, 
        'F1_Score': f1_defective,
        'MCC': mcc_score
    }


if __name__ == '__main__':
    results = []
    print("=" * 60)
    print("ğŸ§  PyTorch ì‹ ê²½ë§ ë¶„ë¥˜ê¸° ë¶„ì„ ì‹œì‘")
    print("=" * 60)

    for name in DATASET_NAMES:
        result = train_and_evaluate_pytorch(name)
        if result:
            results.append(result)

    if results:
        # ì¶œë ¥ í…Œì´ë¸” í—¤ë”ì— MCC ì¶”ê°€
        headers = ["Dataset", "Accuracy", "F1 (Defective)", "MCC"]
        table = [
            [
                r['Dataset'], 
                f"{r['Accuracy']:.4f}", 
                f"{r['F1_Score']:.4f}",
                f"{r['MCC']:.4f}"
            ] for r in results
        ]
        
        print("\n" + tabulate(table, headers=headers, tablefmt="fancy_grid"))

        # Save detailed results to CSV
        df_res = pd.DataFrame(results)
        version = datetime.now().strftime('%m%d_%H%M%S')
        df_res.to_csv(f'dnn_results_{version}.csv', index=False)
        print("\nğŸ’¾ ê²°ê³¼ê°€ 'dnn_results.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")