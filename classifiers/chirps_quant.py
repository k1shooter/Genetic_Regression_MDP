# classifiers/chirps_pdp_piecewise.py

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.inspection import partial_dependence
from scipy.stats import gaussian_kde
from scipy.signal import find_peaks
import platform
import warnings
from util import load_data

warnings.filterwarnings("ignore")



DATASET_NAMES = ['CM1', 'JM1', 'KC1'] 

def get_primary_chirps_threshold(model, feature_idx):
    """
    [CHIRPS Logic]
    ê°€ì¥ ê°•ë ¥í•œ ë¶„ê¸°ì (Primary Threshold)ê³¼ ê·¸ ì§€ì ì˜ ì•ˆì •ì„±(Stability/Density)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    thresholds = []
    for estimator in model.estimators_:
        tree = estimator.tree_
        feature_indices = tree.feature
        threshold_values = tree.threshold
        mask = feature_indices == feature_idx
        thresholds.extend(threshold_values[mask])
    
    # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ë¶„ê¸°ì  ì—†ìŒ
    if len(thresholds) < 10:
        return None, 0.0

    try:
        # KDEë¡œ ë°€ë„ ì¶”ì •
        density = gaussian_kde(thresholds, bw_method='silverman')
        min_th, max_th = np.percentile(thresholds, [1, 99])
        xs = np.linspace(min_th, max_th, 200)
        ys = density(xs)
        
        peaks, _ = find_peaks(ys)
        if len(peaks) == 0:
            return None, 0.0

        # ê°€ì¥ ë†’ì€ Peak(ê°€ì¥ ë¹ˆë²ˆí•œ í•©ì˜ì ) í•˜ë‚˜ë¥¼ ë°˜í™˜
        best_idx = np.argmax(ys[peaks])
        peak_idx = peaks[best_idx]
        
        split_point = xs[peak_idx]
        stability_score = ys[peak_idx] # ë°€ë„ ë†’ì´ (=Stability ëŒ€ìš©)
        
        return split_point, stability_score
        
    except Exception:
        return None, 0.0

def fit_piecewise_linear(pdp_x, pdp_y, split_point):
    """
    [êµ¬ê°„ ì„ í˜• íšŒê·€]
    """
    # 1. ë¶„ê¸°ì ì´ ìœ íš¨í•œì§€ í™•ì¸
    if split_point is None or split_point <= pdp_x.min() or split_point >= pdp_x.max():
        lr = LinearRegression()
        lr.fit(pdp_x.reshape(-1, 1), pdp_y)
        return [(pdp_x, lr.predict(pdp_x.reshape(-1, 1)), lr.coef_[0])], "Linear"

    # 2. ë°ì´í„° ë¶„í• 
    mask_left = pdp_x <= split_point
    mask_right = pdp_x > split_point
    
    if np.sum(mask_left) < 2 or np.sum(mask_right) < 2:
        lr = LinearRegression()
        lr.fit(pdp_x.reshape(-1, 1), pdp_y)
        return [(pdp_x, lr.predict(pdp_x.reshape(-1, 1)), lr.coef_[0])], "Linear (Not enough data)"

    # 3. ê°ê° í”¼íŒ…
    fits = []
    
    # Left
    x_left = pdp_x[mask_left].reshape(-1, 1)
    y_left = pdp_y[mask_left]
    lr_left = LinearRegression()
    lr_left.fit(x_left, y_left)
    fits.append((pdp_x[mask_left], lr_left.predict(x_left), lr_left.coef_[0]))
    
    # Right
    x_right = pdp_x[mask_right].reshape(-1, 1)
    y_right = pdp_y[mask_right]
    lr_right = LinearRegression()
    lr_right.fit(x_right, y_right)
    fits.append((pdp_x[mask_right], lr_right.predict(x_right), lr_right.coef_[0]))
    
    return fits, "Piecewise"

def save_piecewise_plot(pdp_x, pdp_y, fits, split_point, stability, importance, feature_name, dataset_name, save_dir):
    plt.figure(figsize=(10, 6))
    
    # ì•„ì›ƒë¼ì´ì–´ ì œê±° (ì‹œê°í™”ìš©)
    limit_idx = int(len(pdp_x) * 0.95)
    x_vis_max = pdp_x[limit_idx]
    
    mask_vis = pdp_x <= x_vis_max
    plt.plot(pdp_x[mask_vis], pdp_y[mask_vis], label='PDP (Actual)', color='lightgray', linewidth=4, alpha=0.6)
    
    colors = ['blue', 'red']
    labels = ['Before Split', 'After Split']
    slopes = []
    
    for i, (x_seg, y_pred, slope) in enumerate(fits):
        mask_seg = x_seg <= x_vis_max
        if np.sum(mask_seg) > 0:
            plt.plot(x_seg[mask_seg], y_pred[mask_seg], 
                     label=f'{labels[i]} (Slope={slope:.4f})', 
                     color=colors[i], linestyle='--', linewidth=2)
        slopes.append(slope)

    if split_point and split_point <= x_vis_max:
        plt.axvline(x=split_point, color='green', linestyle=':', linewidth=2, 
                    label=f'Split ({split_point:.2f}, Stab:{stability:.2f})')

    plt.legend()
    # ì œëª©ì— ì¤‘ìš”ë„ì™€ ì•ˆì •ì„± í‘œì‹œ
    title_str = (f"Feature: {feature_name} ({dataset_name})\n"
                 f"Importance: {importance:.4f} | Split Stability: {stability:.2f}")
    plt.title(title_str)
    plt.xlabel(f"{feature_name}")
    plt.ylabel("Impact (Defect Probability)")
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    filename = f"{dataset_name}_{feature_name}_piecewise.png".replace(" ", "_").replace("/", "_")
    plt.savefig(os.path.join(save_dir, filename))
    plt.close()
    
    return slopes

def analyze_dataset_piecewise(dataset_name):
    print(f"\nğŸš€ Analyzing Dataset (Piecewise + Metrics): {dataset_name}")
    X_train, y_train, X_test, y_test = load_data(dataset_name, data_type='rf')
    
    if X_train is None:
        return

    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)
    model.fit(X_train, y_train)
    
    feature_names = X_train.columns.tolist()
    
    # Feature Importance ê°€ì ¸ì˜¤ê¸°
    importances = model.feature_importances_
    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ì¸ë±ìŠ¤
    indices = np.argsort(importances)[::-1][:5] 
    
    save_dir = f"analysis_results/Piecewise/{dataset_name}"
    os.makedirs(save_dir, exist_ok=True)
    
    formulas = []

    for idx in indices:
        f_name = feature_names[idx]
        imp_val = importances[idx]  # [ì¶”ê°€] ì¤‘ìš”ë„ ê°’
        
        # 1. PDP ìƒì„±
        pdp_results = partial_dependence(model, X_train, features=[idx], grid_resolution=100)
        pdp_x = pdp_results['grid_values'][0]
        pdp_y = pdp_results['average'][0]
        
        # 2. CHIRPS ë¶„ê¸°ì  ë° ì•ˆì •ì„± ì°¾ê¸° [ìˆ˜ì •]
        split_point, stability = get_primary_chirps_threshold(model, idx)
        
        # 3. êµ¬ê°„ë³„ í”¼íŒ…
        fits, fit_type = fit_piecewise_linear(pdp_x, pdp_y, split_point)
        
        # 4. ì‹œê°í™” (ì¤‘ìš”ë„/ì•ˆì •ì„± ì •ë³´ ì „ë‹¬) [ìˆ˜ì •]
        slopes = save_piecewise_plot(pdp_x, pdp_y, fits, split_point, stability, imp_val, f_name, dataset_name, save_dir)
        
        # 5. ìˆ˜ì‹ í…ìŠ¤íŠ¸ ìƒì„±
        if fit_type == "Piecewise":
            slope_before = slopes[0]
            slope_after = slopes[1]
            formula_str = (f"IF({f_name} <= {split_point:.2f}, "
                           f"{slope_before:.3f} * {f_name}, "
                           f"{slope_after:.3f} * {f_name})")
        else:
            formula_str = f"{slopes[0]:.3f} * {f_name} (Linear)"
            
        formulas.append({
            'Feature': f_name,
            'Importance': imp_val,       # [ì¶”ê°€]
            'Split_Stability': stability,# [ì¶”ê°€]
            'Fit_Type': fit_type,
            'Split_Point': split_point if split_point else "N/A",
            'Slope_Before': slopes[0],
            'Slope_After': slopes[1] if len(slopes) > 1 else "N/A",
            'Formula': formula_str
        })
        print(f"  - {f_name}: Imp={imp_val:.3f}, Stab={stability:.2f}, Type={fit_type}")

    # ê²°ê³¼ ì €ì¥
    pd.DataFrame(formulas).to_csv(os.path.join(save_dir, "piecewise_formulas_metrics.csv"), index=False)
    print(f"ğŸ’¾ Results saved to {save_dir}/piecewise_formulas_metrics.csv")

if __name__ == "__main__":
    if not os.path.exists("../data"):
        print("âš ï¸ Warning: '../data' directory not found.")
    
    for name in DATASET_NAMES:
        try:
            analyze_dataset_piecewise(name)
        except Exception as e:
            print(f"Error: {e}")
            import traceback
            traceback.print_exc()