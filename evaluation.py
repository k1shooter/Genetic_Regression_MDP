import os
import sys
import glob
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tabulate import tabulate
from datetime import datetime

# í•œê¸€ í°íŠ¸ ì„¤ì • (í•„ìš”ì‹œ ì‹œìŠ¤í…œì— ë§ëŠ” í°íŠ¸ë¡œ ë³€ê²½)
plt.rcParams['font.family'] = 'Malgun Gothic' # Windows
plt.rcParams['axes.unicode_minus'] = False

def find_latest_result(pattern):
    """
    ì£¼ì–´ì§„ íŒ¨í„´ì— ë§ëŠ” ê°€ì¥ ìµœì‹  CSV íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    """
    files = glob.glob(pattern)
    if not files:
        return None
    return max(files, key=os.path.getctime)

def load_results():
    """
    ê° ëª¨ë¸ì˜ ìµœì‹  ê²°ê³¼ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ í†µí•©í•©ë‹ˆë‹¤.
    """
    print("ğŸ“‚ ìµœì‹  ê²°ê³¼ íŒŒì¼ ë¡œë”© ì¤‘...")
    
    # 1. DNN (Tuned)
    dnn_file = find_latest_result("optuna_dnn_results *.csv")
    if dnn_file:
        dnn_df = pd.read_csv(dnn_file)
        # ì»¬ëŸ¼ëª… í†µì¼
        dnn_df = dnn_df.rename(columns={'DNN_Acc': 'Acc', 'DNN_F1': 'F1', 'DNN_MCC': 'MCC'})
        dnn_df['Model'] = 'DNN (Tuned)'
    else:
        print("âš ï¸ DNN ê²°ê³¼ íŒŒì¼ ì—†ìŒ (optuna_dnn_results.csv)")
        dnn_df = pd.DataFrame()

    # 2. Random Forest (Tuned)
    rf_file = find_latest_result("optuna_rf_results *.csv")
    if rf_file:
        rf_df = pd.read_csv(rf_file)
        rf_df = rf_df.rename(columns={'RF_Acc': 'Acc', 'RF_F1': 'F1', 'RF_MCC': 'MCC'})
        rf_df['Model'] = 'RF (Tuned)'
    else:
        print("âš ï¸ RF ê²°ê³¼ íŒŒì¼ ì—†ìŒ (optuna_rf_results.csv)")
        rf_df = pd.DataFrame()

    # 3. Naive Bayes
    nb_file = find_latest_result("naive_bayes_results_*.csv")
    if nb_file:
        nb_df = pd.read_csv(nb_file)
        nb_df = nb_df.rename(columns={'Accuracy': 'Acc', 'F1_Score': 'F1'})
        if 'MCC' not in nb_df.columns: nb_df['MCC'] = 0.0 # NBì— MCCê°€ ì—†ë‹¤ë©´ 0 ì²˜ë¦¬
        nb_df['Model'] = 'Naive Bayes'
    else:
        print("âš ï¸ Naive Bayes ê²°ê³¼ íŒŒì¼ ì—†ìŒ")
        nb_df = pd.DataFrame()

    # 4. GP (GA-MO)
    gp_file = find_latest_result("ga_mo_results_*.csv")
    if gp_file:
        gp_raw = pd.read_csv(gp_file)
        # GPëŠ” ì—¬ëŸ¬ í•´ê°€ ë‚˜ì˜¤ë¯€ë¡œ, ê° ë°ì´í„°ì…‹ë³„ë¡œ MCCê°€ ê°€ì¥ ë†’ì€ í•˜ë‚˜ë§Œ ì„ íƒ
        # ì»¬ëŸ¼ëª… ì •ë¦¬ (Test F1 -> F1, Test MCC -> MCC ë“±)
        gp_raw.columns = gp_raw.columns.str.strip()
        rename_map = {'Test F1': 'F1', 'Test_F1': 'F1', 
                      'Test MCC': 'MCC', 'Test_MCC': 'MCC',
                      'Test Acc': 'Acc', 'Test_Acc': 'Acc',
                      'Complexity': 'Cplx'}
        gp_raw = gp_raw.rename(columns=rename_map)
        
        # Targetì´ ìˆë‹¤ë©´ MCC ìµœì í™” ê²°ê³¼ ìš°ì„ 
        if 'Target' in gp_raw.columns:
            mcc_target = gp_raw[gp_raw['Target'].str.upper() == 'MCC']
            if not mcc_target.empty:
                gp_best = mcc_target.sort_values(['Dataset', 'MCC'], ascending=[True, False]).drop_duplicates('Dataset')
            else:
                gp_best = gp_raw.sort_values(['Dataset', 'MCC'], ascending=[True, False]).drop_duplicates('Dataset')
        else:
            gp_best = gp_raw.sort_values(['Dataset', 'MCC'], ascending=[True, False]).drop_duplicates('Dataset')
            
        gp_df = gp_best[['Dataset', 'Acc', 'F1', 'MCC', 'Cplx', 'Formula']].copy()
        gp_df['Model'] = 'GP (Ours)'
    else:
        print("âš ï¸ GP ê²°ê³¼ íŒŒì¼ ì—†ìŒ")
        gp_df = pd.DataFrame()

    # í†µí•©
    all_df = pd.concat([dnn_df, rf_df, nb_df, gp_df], ignore_index=True)
    return all_df

def plot_comparison(df):
    """
    ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„ ìƒì„± ë° ì €ì¥
    """
    if df.empty: return

    save_dir = "comparison_plots"
    os.makedirs(save_dir, exist_ok=True)
    
    metrics = ['F1', 'MCC', 'Acc']
    
    for metric in metrics:
        if metric not in df.columns: continue
        
        plt.figure(figsize=(14, 7))
        sns.barplot(data=df, x='Dataset', y=metric, hue='Model', palette='viridis')
        plt.title(f'Model Comparison - {metric} Score', fontsize=15)
        plt.ylabel(metric)
        plt.ylim(-0.1, 1.1) # MCCëŠ” -1ê¹Œì§€ ê°ˆ ìˆ˜ ìˆì§€ë§Œ ì‹œê°í™” í¸ì˜ìƒ
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.tight_layout()
        
        filename = f"{save_dir}/comparison_{metric}.png"
        plt.savefig(filename)
        plt.close()
        print(f"ğŸ“Š {metric} ë¹„êµ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {filename}")

def print_summary(df):
    """
    ìµœì¢… ìš”ì•½ í…Œì´ë¸” ì¶œë ¥
    """
    if df.empty: return

    # í”¼ë²— í…Œì´ë¸”ë¡œ ë³€í™˜í•˜ì—¬ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
    # (Datasetì„ í–‰ìœ¼ë¡œ, Modelì˜ ê° ì§€í‘œë¥¼ ì—´ë¡œ)
    print("\n" + "="*80)
    print("ğŸ† Final Performance Summary (Sorted by MCC)")
    print("="*80)
    
    # ì£¼ìš” ì§€í‘œì¸ MCC ê¸°ì¤€ìœ¼ë¡œ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ ì •
    best_models = df.loc[df.groupby('Dataset')['MCC'].idxmax()]
    
    table_data = []
    for _, row in best_models.iterrows():
        table_data.append([
            row['Dataset'], 
            row['Model'], 
            f"{row['MCC']:.4f}", 
            f"{row['F1']:.4f}", 
            f"{row['Acc']:.4f}"
        ])
        
    headers = ["Dataset", "Best Model (MCC)", "MCC", "F1", "Acc"]
    print(tabulate(table_data, headers=headers, tablefmt="fancy_grid"))
    
    # ì „ì²´ ìƒì„¸ í…Œì´ë¸” ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    df.sort_values(['Dataset', 'Model']).to_csv(f"final_evaluation_summary_{timestamp}.csv", index=False)
    print(f"\nğŸ’¾ ì „ì²´ ìƒì„¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: final_evaluation_summary_{timestamp}.csv")

    # Formula ë¹„êµ (GP vs RF)
    compare_formulas(df)

def compare_formulas(df):
    print("\n" + "="*80)
    print("ğŸ” Interpretability Comparison: GP vs RF (Simple Tree)")
    print("="*80)
    
    # GP Formula
    gp_formulas = df[df['Model'] == 'GP (Ours)'][['Dataset', 'Cplx', 'Formula']]
    
    # RF Formula (ë³„ë„ íŒŒì¼ì—ì„œ ë¡œë“œ)
    rf_formula_file = find_latest_result("random_forest_formulas_*.csv")
    if rf_formula_file:
        rf_raw = pd.read_csv(rf_formula_file)
        # ì²« ë²ˆì§¸ íŠ¸ë¦¬(Tree_Index=0)ë¥¼ ëŒ€í‘œë¡œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê°€ì¥ ê°„ë‹¨í•œ ê²ƒ ì„ íƒ
        rf_formulas = rf_raw[rf_raw['Tree_Index'] == 0][['Dataset', 'Formula']].rename(columns={'Formula': 'RF_Formula'})
    else:
        rf_formulas = pd.DataFrame(columns=['Dataset', 'RF_Formula'])

    # ë³‘í•©
    merged = pd.merge(gp_formulas, rf_formulas, on='Dataset', how='left')
    
    for _, row in merged.iterrows():
        print(f"\nğŸ“Œ Dataset: {row['Dataset']}")
        print(f"   [GP] (Cplx: {row['Cplx']}): {row['Formula']}")
        rf_f = str(row['RF_Formula'])
        # RF ìˆ˜ì‹ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
        if len(rf_f) > 100: rf_f = rf_f[:97] + "..."
        print(f"   [RF] (Tree #0): {rf_f}")

if __name__ == "__main__":
    # 1. ê²°ê³¼ íŒŒì¼ ë¡œë“œ ë° í†µí•©
    final_df = load_results()
    
    if not final_df.empty:
        # 2. ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        plot_comparison(final_df)
        
        # 3. ìš”ì•½ ë° ìˆ˜ì‹ ë¹„êµ ì¶œë ¥
        print_summary(final_df)
    else:
        print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê° ëª¨ë¸ ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")